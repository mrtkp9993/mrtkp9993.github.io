<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>A Brief Introduction to Bayesian Statistics</title>
      <!-- HTML Meta Tags -->
    <meta name="description" content="Notes & Articles about math and statistics.">

    <!-- Facebook Meta Tags -->
    <meta property="og:url" content="https://muratkoptur.com/articles_index.html">
    <meta property="og:type" content="website">
    <meta property="og:title" content="Articles - Murat Koptur - Data Scientist">
    <meta property="og:description" content="Notes & Articles about math and statistics.">
    <meta property="og:image" content="https://muratkoptur.com/articles_og.png">

    <!-- Twitter Meta Tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta property="twitter:domain" content="muratkoptur.com">
    <meta property="twitter:url" content="https://muratkoptur.com/articles_index.html">
    <meta name="twitter:title" content="Articles - Murat Koptur - Data Scientist">
    <meta name="twitter:description" content="Notes & Articles about math and statistics.">
    <meta name="twitter:image" content="https://muratkoptur.com/articles_og.png">

  <!-- Meta Tags Generated via https://www.opengraph.xyz -->
        
    <link rel="stylesheet" href="https://latex.now.sh/style.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            }
        };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body class="libertinus">
    <header>
        <h1>A Brief Introduction to Bayesian Statistics</h1>
        <p class="author">Murat Koptur <br> VERSION 0.2 - 23/03/2023</p>
    </header>

    <div class="abstract">
        <blockquote>
            Achieving replicability is important for making research progress. If findings are not replicable, then
            prediction and theory development are stifled. If findings are replicable, then interrogation of their
            meaning
            and validity can
            advance knowledge. Assessing replicability can be productive for generating and testing hypotheses by
            actively
            confronting current understandings to identify weaknesses and spur innovation.
            <cite>â€” Brian Nosek</cite>
        </blockquote>
    </div>

    <main>
        <article class="indent-pars">
            <h2>Fundamental Definitions</h2>
            <p>
                Probability theory is a mathematical framework that allows us to reason about experiments whose outcome
                is
                uncertain. A probabilistic model is a mathematical model of a probabilistic experiment that satisfies
                certain
                mathematical properties (the axioms of probability theory), and which allows us to calculate
                probabilities
                and
                to reason about the likely outcomes of the experiment. <label for="sn-1"
                    class="sidenote-toggle sidenote-number"></label>
                <input type="checkbox" id="sn-1" class="sidenote-toggle" />
                <span class="sidenote">Source:
                    <a
                        href="https://ocw.mit.edu/courses/6-436j-fundamentals-of-probability-fall-2018/c37dc8b61cdf6bde689a627bfa5b4942_MIT6_436JF18_lec01.pdf">
                        Link
                    </a>
                </span>
            </p>
            <div class="definition">
                A probabilistic model is defined by a triple $(\Omega, \mathcal{F}, \mathbb{P}) $, called a probability
                space, consists of the following three elements:
                <ol>
                    <li>$\Omega $ is the sample space, the set of possible experiment outcomes.</li>
                    <li>$\mathcal{F} $ is a $\sigma $-algebra, a collection of subsets of $\Omega $.</li>
                    <li>$\mathbb{P} $ is a probability measure, a function that assigns a nonnegative probability to
                        every
                        set in the $\sigma $-algebra $\mathcal{F} $. <label for="sn-2"
                            class="sidenote-toggle sidenote-number"></label>
                        <input type="checkbox" id="sn-2" class="sidenote-toggle" />
                        <span class="sidenote">Source:
                            <a
                                href="https://ocw.mit.edu/courses/6-436j-fundamentals-of-probability-fall-2018/c37dc8b61cdf6bde689a627bfa5b4942_MIT6_436JF18_lec01.pdf">
                                Link
                            </a>
                        </span>
            </div>
            <p>
                We'll not give measure-theoretical introduction here. For more measure-theoretical introduction to
                probability
                theory, please read <sup>2</sup>.
            </p>
            <div class="definition">Let $A $ and $B $ be events in discrete sample space $S, $ and $p(B)\neq0 $.
                Then Bayes' theorem is stated as
                $$
                p(A|B)=\frac{p(B|A)p(A)}{p(B)}.
                $$
                In this formula
                <ul>
                    <li>
                        $p(A|B) $ is the probability of event $A $ occuring given that $B $ is true. It is also called
                        the
                        posterior probability of $A $ given $B $.
                    </li>
                    $p(B|A) $ is the probability of event $B $ occurring given that $A $ is true. It can be also be
                    interpreted as the likelihood of $A $ given a fixed $B $.
                    </li>
                    <li>$p(A) $ and $p(B) $ are the probabilities of observing $A $ and $B $ respectively without any
                        conditions; they are known as the prior probability and marginal probability.
                        <label for="sn-3" class="sidenote-toggle sidenote-number"></label>
                        <input type="checkbox" id="sn-3" class="sidenote-toggle" />
                        <span class="sidenote">Source: <a
                                href="https://www.wikiwand.com/en/Bayes%27_theorem">Link</a></span>
                    </li>
                </ul>

            </div>
            <p>
                Suppose that we have a medical test with following probabilities:
            <ul>
                <li>Disease occuring rate in a general population is $1\% $,</li>
                <li>If you have the disease, the test shows that you do with probability $80\% $, </li>
                <li>If you don't have the disease, it shows that you do with probability $9.6\% $. </li>
            </ul>
            The question is, how likely is that you have the disease if the test is positive?</p>
            <p>
                Let's use following notation: $H $ is being healthy, $S $ is being sick, $+ $ is positive test result,
                and
                $- $ is a negative test result.
                Then, this probability can be calculated
                as
                $$
                \begin{aligned} p(S|+) &= \frac{p(+|S)p(S)}{p(+)} \\
                &= \frac{0.8\times 0.01}{0.01\times0.8 + 0.99\times0.096} \\
                &= 0.077 \end{aligned}
                $$

                So, the probability of being sick is $7.8\%$.
                Let's think the doctor wants to re-test the patient to be sure. If we update the probability of being
                sick with $7.8\%$, then the probability of being sick if the test is positive becomes

                $$
                p(S|+) = \frac{0.8\times 0.077}{0.077\times0.8 + 0.923\times0.096} \approx 0.41
                $$

                After the second test, if second test is positive, the probability of being sick is nearly $41\%$.
                This example shows the power of Bayes' theorem, it allows to update our beliefs when our data is
                updated.
            </p>
            <p>
                There is another way to interpret Bayes' theorem: Diachronic interpretation.
                Suppose that $H $ is our hypothesis and $D $ is our data. Then Bayes' theorem can be written as
                $$
                p(H|D) = \frac{p(D|H)p(H)}{p(D)}.
                $$
                Here is <label for="sn-4" class="sidenote-toggle sidenote-number"></label>
                <input type="checkbox" id="sn-4" class="sidenote-toggle" />
                <span class="sidenote">Source: <a
                        href="https://www.researchgate.net/publication/338896961_Bayesci_Istatistige_Giris">Link</a></span>:
            <ul>
                <li>
                    $p(H) $ is the prior probability which is probability of hypothesis $H $ before data $D $ is
                    observed / collected.
                </li>
                <li>
                    $p(D|H) $ is the probability of the data under the hypothesis, called the likelihood.
                </li>
                <li>
                    $p(D) $ is the probability of the data under any hypothesis, called the normalizing constant. This
                    constant amkes the posterios density integrate to one.
                </li>
                <li>
                    $p(H|D) $ is the probability of the hypothesis after data is collected, called the posterior
                    probability.
                </li>
            </ul>
            In practice, $p(D) $ is difficult to calculate in a closed-form, so one often uses the following adaptation
            of
            Bayes' formula
            $$
            p(H|D) \propto p(D|H)p(H)
            $$
            </p>
            <p>
                As a second example, let's consider the famous Monty Hall problem. The problem is stated as follows in
                Parade
                magazine in 1990:
            <blockquote>
                Suppose you're on a game show, and you're given the choice of three doors: Behind one door is a car;
                behind
                the others,
                goats. You pick a door, say No. 1, and the host, who knows what's behind the doors, opens another door,
                say
                No. 3, which
                has a goat. He then says to you, "Do you want to pick door No. 2?" Is it to your advantage to switch
                your
                choice?<label for="sn-5" class="sidenote-toggle sidenote-number"></label>
                <input type="checkbox" id="sn-5" class="sidenote-toggle" />
                <span class="sidenote">Source: <a href="https://www.wikiwand.com/en/Monty_Hall_problem">Link</a></span>
            </blockquote>
            </p>
            <p>
                Let's look at the probability table of the problem:
            <table>
                <thead>
                    <tr>
                        <th>Door 1</th>
                        <th>Door 2</th>
                        <th>Door 3</th>
                        <th>Result if not switch doors</th>
                        <th>Result if switch doors</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Car</td>
                        <td>Goat</td>
                        <td>Goat</td>
                        <td>Wins Car</td>
                        <td>Losts Car</td>
                    </tr>
                    <tr>
                        <td>Goat</td>
                        <td>Car</td>
                        <td>Goat</td>
                        <td>Losts Car</td>
                        <td>Wins Car</td>
                    </tr>
                    <tr>
                        <td>Goat</td>
                        <td>Goat</td>
                        <td>Car</td>
                        <td>Losts Car</td>
                        <td>Wins Car</td>
                    </tr>
                </tbody>
            </table>
            If you switch the door, you will win the car with probability $2/3$, so the switching strategy is a better
            strategy than not switching the doors.
            </p>
            <p>Let's examine the problem with Bayes' theorem now. Assume that you choose Door 1, and the host opens Door
                2.
                Then:
            <ul>
                <li>If the car is behind Door 1, the host can open Door 2 or Door 3.
                    So
                    $$
                    p(A|D)=\frac{\frac{1}{2}\times\frac{1}{3}}{\frac{1}{2}\times\frac{1}{3}+0\times\frac{1}{3}+1*\frac{1}{3}}=\frac{1}{3}.
                    $$
                </li>
                <li>If the car is behind Door 2, the host will not open Door 2. So $$
                    p(B|D)=\frac{0\times\frac{1}{3}}{\frac{1}{2}\times\frac{1}{3}+0\times\frac{1}{3}+1*\frac{1}{3}}=0.
                    $$
                </li>
                <li>If the car is behind Door 3, the host will open Door 2 all the time. So
                    $$
                    p(C|D)=\frac{1\times\frac{1}{3}}{\frac{1}{2}\times\frac{1}{3}+0\times\frac{1}{3}+1*\frac{1}{3}}=\frac{1}{3}.
                    $$
                </li>
            </ul>
            If we calculate the posterior probability for each hypothesis, we have the following results:
            <table>
                <thead>
                    <tr>
                        <th>Hypothesis</th>
                        <th>Prior probability $p(H) $</th>
                        <th>Likelihood $p(D|H) $</th>
                        <th>Posterior probability $p(H|D) $</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>A</td>
                        <td>1/3</td>
                        <td>1/2</td>
                        <td>1/3</td>
                    </tr>
                    <tr>
                        <td>B</td>
                        <td>1/3</td>
                        <td>0</td>
                        <td>0</td>
                    </tr>
                    <tr>
                        <td>C</td>
                        <td>1/3</td>
                        <td>1</td>
                        <td>2/3</td>
                    </tr>
                </tbody>
            </table>
            </p>

            <h2>Differences between Frequentist and Bayesian Statistics</h2>
            <p>
                Regardless of which statistical approach, any statistical inference paradigm deals with three things:
            <ul>
                <li>The quantities which we want to estimate or test, called parameters.</li>
                <li>Observed and/or collected data.</li>
                <li>Models which help us to relate data and parameters.</li>
            </ul>
            In the frequentist view of probability:
            <ul>
                <li>Data is random because they are observations of stochastic processes.</li>
                <li>Model parameters are fixed because they remain constant during the sampling process.</li>
            </ul>
            In Bayesian view of probability:
            <ul>
                <li>Data is fixed.</li>
                <li>Model parameters are treated and described probabilistically. And they are defined via probability
                    distributions.</li>
            </ul>
            </p>

            <h2>Bayesian Inference</h2>
            <p>
                Bayesian inference can be described in three steps:
                <label for="sn-6" class="sidenote-toggle sidenote-number"></label>
                <input type="checkbox" id="sn-6" class="sidenote-toggle" />
                <span class="sidenote">Source: A. Gelman, J. B. Carlin, H. S. Stern, D. B. Dunson, A. Vehtari,D. B.
                    Rubin, Bayesian data analysis, third edition, 2013.</span>
            <ol>
                <li>Setting up full probability model: For all observed and unobserved quantities, a joint probability
                    distribution must be defined.
                    <br>
                    Suppose $y $ is observed data and $\theta $ is parameters. Then joint probability distribution is
                    defined as
                    $$
                    p(\theta, y) = p(y|\theta)p(\theta).
                    $$
                    Here, $p(\theta) $ is prior distribution and $p(y|\theta) $ is the sampling distribution.
                </li>
                <li>
                    Calculating the posterior distribution: After the data were observed, posterior distribution will be
                    calculated with Bayes' theorem:
                    $$
                    p(\theta|y)=\frac{p(\theta)p(y|\theta)}{p(y)}\propto p(\theta)p(y|\theta)
                    $$
                </li>
                <li>
                    Model diagnostics: How well does the model fit the data? How sensitive are the results to the
                    modeling assumptions in step 1? We will dive into tests a few chapters later.
                </li>
            </ol>

            Posterior distribution has all the information about our parameters. But, in practice, we need some tools to
            summarize
            information. Graphically, if our parameter vector has low dimension (1-2), we can plot the distribution. If
            our parameter vector has higher
            dimension, we can plot marginal posterior distributions.

            Numerically, we can use point estimation and interval estimation methods. For point estimations, we have
            different options:
            <ul>
                <li>Posterior mode
                    $$
                    \hat{\theta}=\max_\theta[p(\theta|y)]
                    $$
                </li>
                <li>
                    Posterior mean
                    $$
                    \hat{\theta}=\mathbb{E}[\theta|y]=\int{y p(\theta|y) d\theta}
                    $$
                </li>
            </ul>
            For interval estimations, we can use:
            <ul>
                <li>(Credible interval) A $100(1-\alpha)\%$ credible interval for parameter $\theta $ is an interval
                    $[a, b] $ such that the probability that $\theta $ lies in the interval is $1-\alpha$<label
                        for="sn-7" class="sidenote-toggle sidenote-number"></label>
                    <input type="checkbox" id="sn-7" class="sidenote-toggle" />
                    <span class="sidenote">Source: <a
                            href="https://web.stanford.edu/class/archive/cs/cs109/cs109.1218/files/student_drive/8.2.pdf">Link</a></span>:
                    $$
                    p(\theta\in[a,b])=1-\alpha
                    $$
                    If parameter vector has a dimension bigger than one, this is called as credible region.
                </li>
                <li>Highest density region is the region with $100(1-\alpha)\%$ probability of containing $\theta$ with
                    the shortest total length.</li>
            </ul>
            </p>

            <h2>Prior Distribution Recommendations</h2>
            <p>Stan (Bayesian inference package) has a great <a
                    href="https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations">wiki</a> about selecting
                prior distributions for analyses.</p> Historically, due to lack of necessary computation power and
            methods,
            conjugate priors were mostly selected for ease of calculation of the posterior. Today with faster computers
            and
            MCMC sampling methods, nearly any arbitrary posterior can be sampled.
            </p>

            To be continued...

        </article>
    </main>

</body>

</html>